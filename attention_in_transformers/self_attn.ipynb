{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aVYI4Jz77xkD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coding the self-attention architecture"
      ],
      "metadata": {
        "id": "Dt9MpNW1Hml5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttn(nn.Module):\n",
        "  def __init__(self, dim_model = 2,\n",
        "               row_dim = 0,\n",
        "               col_dim = 1):\n",
        "    ## dim_model = the number of embedding values per token.\n",
        "    ##           Because we want to be able to do the math by hand, we've\n",
        "    ##           the default value for d_model=2.\n",
        "    ##           However, in \"Attention Is All You Need\" d_model=512\n",
        "    ##\n",
        "    ## row_dim, col_dim = the indices we should use to access rows or columns\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    ## Initialize the Weights (W) that we'll use to create the\n",
        "    ## query (q), key (k) and value (v) for each token\n",
        "    ## NOTE: A lot of implementations include bias terms when\n",
        "    ##       creating the the queries, keys, and values, but\n",
        "    ##       the original manuscript that described Attention,\n",
        "    ##       \"Attention Is All You Need\" did not, so we won't either\n",
        "\n",
        "\n",
        "    self.W_q = nn.Linear(in_features = dim_model,\n",
        "                        out_features = dim_model,\n",
        "                        bias = False)\n",
        "    self.W_k = nn.Linear(in_features = dim_model,\n",
        "                        out_features = dim_model,\n",
        "                        bias = False)\n",
        "    self.W_v = nn.Linear(in_features = dim_model,\n",
        "                        out_features = dim_model,\n",
        "                        bias = False)\n",
        "\n",
        "    self.row_dim = row_dim\n",
        "    self.col_dim = col_dim\n",
        "\n",
        "  def forward(self, token_embeddings):\n",
        "\n",
        "      ## Create the query, key and values using the encoding numbers\n",
        "      ## associated with each token (token encodings)\n",
        "\n",
        "\n",
        "    q = self.W_q(token_embeddings) #tok_emb x Wq = Q\n",
        "    k = self.W_k(token_embeddings) #tok_emb x Wk = K\n",
        "    v = self.W_v(token_embeddings) #tok_emb x Wv = V\n",
        "\n",
        "    sim_score = torch.matmul(q, k.transpose(dim0=self.row_dim, dim1=self.col_dim)) ## Compute similarities scores: (q * k^T)\n",
        "\n",
        "    scaled_sim_score = sim_score / (k.shape[self.col_dim] ** 0.5) ## Scale the similarities by dividing by sqrt(k.col_dim)\n",
        "\n",
        "    ## Apply softmax to determine what percent of each tokens' value to\n",
        "    ## use in the final attention values.\n",
        "\n",
        "    attn_percent = F.softmax(scaled_sim_score, dim=self.col_dim)\n",
        "\n",
        "    ## Scale the values by their associated percentages and add them up.\n",
        "    attn_scores = torch.matmul(attn_percent, v)\n",
        "\n",
        "    return attn_scores\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GLlcDCcpDnIj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing out the caluclation of self-attention"
      ],
      "metadata": {
        "id": "M6-s9CmLHpxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_matrix = torch.tensor([[1.16, 0.23],\n",
        "                                  [0.57, 1.36],\n",
        "                                  [4.41, -2.16]])"
      ],
      "metadata": {
        "id": "NbiuoiJ5HcX7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42) #ensure reproducibility"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hvsR3bWILKO",
        "outputId": "e9f8bef9-2875-4768-e7e2-ed236533306e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7dd39bf39870>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sa = SelfAttn(dim_model = 2,\n",
        "              row_dim = 0,\n",
        "              col_dim = 1)"
      ],
      "metadata": {
        "id": "RoicYpIkISMz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sa(embeddings_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPLynJYgIZYk",
        "outputId": "2bb6021d-89fb-490c-c3ea-86dce77f6320"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0100, 1.0641],\n",
              "        [0.2040, 0.7057],\n",
              "        [3.4989, 2.2427]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "validating the math"
      ],
      "metadata": {
        "id": "yFOZcg0jItFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sa.W_q.weight.transpose(0,1) #Wq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_JGCkz1IiW4",
        "outputId": "d75f03b6-a519-4ed8-f4ed-b298aa8314f3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.5406, -0.1657],\n",
              "        [ 0.5869,  0.6496]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sa.W_k.weight.transpose(0,1) #Wk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjTJPUsAJAdi",
        "outputId": "2ae7ad80-bb84-4ba5-ac2c-9f13d7ecb7d0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1549, -0.3443],\n",
              "        [ 0.1427,  0.4153]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sa.W_v.weight.transpose(0,1) #Wv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goT0khcVJE-g",
        "outputId": "d7158a8f-6bb4-4298-f0d9-929315444938"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6233,  0.6146],\n",
              "        [-0.5188,  0.1323]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sa.W_q(embeddings_matrix) #q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdPo8MpEJIsm",
        "outputId": "0e9f572c-db5a-40b6-9288-cc84f0ec697a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7621, -0.0428],\n",
              "        [ 1.1063,  0.7890],\n",
              "        [ 1.1164, -2.1336]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sa.W_k(embeddings_matrix) #k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLbNYnsPJ2ba",
        "outputId": "c734e305-63f4-455d-e32d-cdb094d98f30"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1469, -0.3038],\n",
              "        [ 0.1057,  0.3685],\n",
              "        [-0.9914, -2.4152]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sa.W_v(embeddings_matrix) #v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuPqzzsCJ5kF",
        "outputId": "2dd2a386-71bb-4895-82f5-4824c877f1e9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6038,  0.7434],\n",
              "        [-0.3502,  0.5303],\n",
              "        [ 3.8695,  2.4246]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zd5jWLgWJ76S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}