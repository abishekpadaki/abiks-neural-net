{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ci01U_E-3kj"
      },
      "source": [
        "Okay, so here i try to build alexnet (from scratch with torch?) kinda breaking it down into smaller blocks for my understanding.\n",
        "\n",
        "this is gonna get messy so if someone else or future me is reading this, apologies in adv."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxkd4Dd0x86j"
      },
      "source": [
        "# The Building Blocks\n",
        "\n",
        "First lets build the core fundamental blocks of alexnet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFeigPjl_MqO"
      },
      "source": [
        "## Understanding the convolution layer\n",
        "\n",
        "a conv layer is a sliding window of sorts that learns 'filters' to detect edges, blobs, curves and so on in images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQPVbg03-dP_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gqn5COTm_iGE",
        "outputId": "6fcc3bf5-899f-45b4-e893-bf3a75f2d108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output shape: torch.Size([1, 8, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "conv = nn.Conv2d(\n",
        "    in_channels=3, #rgb ip\n",
        "    out_channels=8, #num_filters\n",
        "    kernel_size=3, #size of filter (3x3)\n",
        "    stride=1, #step size\n",
        "    padding=1 #add 1 pxl border to keep size\n",
        ")\n",
        "\n",
        "# Dummy image data with batch of 1, 3 channels and 32x32px\n",
        "\n",
        "x = torch.randn(1,3,32,32)\n",
        "\n",
        "out = conv(x)\n",
        "\n",
        "print(\"output shape:\", out.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqevUd0sr24B"
      },
      "source": [
        "What’s happening here?\n",
        "\n",
        "- in_channels: number of channels in the input (3 for RGB images).\n",
        "\n",
        "- out_channels: how many filters to learn (more filters → more feature types).\n",
        "\n",
        "- kernel_size: filter’s width/height.\n",
        "\n",
        "- stride: how far the filter jumps each step.\n",
        "\n",
        "- padding: how many pixels you add around the edges to preserve size.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7CSqp45sXxd"
      },
      "source": [
        "## Ading Non-linearity with ReLU\n",
        "Without non-linear activation, your network is basically a fancy linear equation. AlexNet uses ReLU after each convolution to let the network model complex shapes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWtbfVebrttE",
        "outputId": "3595c804-0939-4340-af9f-c4ee71b98081"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output shape after ReLU torch.Size([1, 8, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "relu = nn.ReLU()\n",
        "out = relu(out)\n",
        "\n",
        "print(\"output shape after ReLU\", out.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peox1IhIvhvO"
      },
      "source": [
        "## Pooling (downsampling)\n",
        "\n",
        "Pooling shrinks the feature map size. AlexNet uses MaxPooling with a kernel of 3 and stride 2 (so it overlaps).\n",
        "Pooling keeps only the strongest activations, making the network less sensitive to small shifts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkYjLZN8s70_",
        "outputId": "aec1a963-29d8-4ee5-a84f-18a15443d06b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After pooling: torch.Size([1, 8, 15, 15])\n"
          ]
        }
      ],
      "source": [
        "pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "out = pool(out)\n",
        "print(\"After pooling:\", out.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojoYsRMMxvkW"
      },
      "source": [
        "Conv → ReLU → Pool\n",
        "This is the fundamental block of AlexNet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7-_2vD05f56"
      },
      "source": [
        "# Understanding the Conv stages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdrOjxMs5ol7"
      },
      "source": [
        "We’ll build the first two stages exactly like the paper: big 11×11 stride-4 opener, overlapping max-pool, then a 5×5 block, another pool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rw3CR_0o5kOt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pA0FpN1e5tvt"
      },
      "outputs": [],
      "source": [
        "#create a dummy img with batch 1, 3 channels. h&w of 224\n",
        "\n",
        "x = torch.zeros(1, 3, 224, 224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iYjPU6I85_u5"
      },
      "outputs": [],
      "source": [
        "conv1 = nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2)\n",
        "relu1 = nn.ReLU(inplace=True)\n",
        "lrn1 = nn.LocalResponseNorm(size=5, alpha=1e-4, beta=0.75, k=2.0) # historical AlexNet quirk for normalization\n",
        "pool1 = nn.MaxPool2d(kernel_size=3, stride=2) # overlapping pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aDUTd4we69vB"
      },
      "outputs": [],
      "source": [
        "conv2 = nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2)\n",
        "relu2 = nn.ReLU(inplace=True)\n",
        "lrn2 = nn.LocalResponseNorm(size=5, alpha=1e-4, beta=0.75, k=2.0)\n",
        "pool2 = nn.MaxPool2d(kernel_size=3, stride=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZZsDusS8TwF",
        "outputId": "63690503-9094-4bc4-ea76-98475e4f8163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "conv1: torch.Size([1, 96, 55, 55])\n",
            "pool1: torch.Size([1, 96, 27, 27])\n",
            "conv2: torch.Size([1, 256, 27, 27])\n",
            "pool2: torch.Size([1, 256, 13, 13])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "  y = conv1(x)\n",
        "  print(\"conv1:\", y.shape)\n",
        "  y= lrn1(y)\n",
        "  y = pool1(y)\n",
        "  print(\"pool1:\", y.shape)\n",
        "  y = conv2(y)\n",
        "  print(\"conv2:\", y.shape)\n",
        "  y = relu2(y)\n",
        "  y = lrn2(y)\n",
        "  y = pool2(y)\n",
        "  print(\"pool2:\", y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYgBkVqi8_zf"
      },
      "source": [
        "conv1 turns 224×224 into 55×55 because stride-4 jumps four pixels at a time. The formula is out = floor((W − K + 2P)/S) + 1 = (224−11+4)/4 +1 = 55.\n",
        "\n",
        "pool1 with 3×3, stride-2 reduces 55→27 ((55−3)/2 + 1 = 27).\n",
        "\n",
        "conv2 keeps it 27×27 (padding 2 on a 5×5 kernel preserves size).\n",
        "\n",
        "pool2 reduces 27→13."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "the 3rd stage consists of 3 more conv layers with ReLU after each, and then ends with a maxpooling layer. (We will skip this and use it in the next part when building the entire structure)\n",
        "\n",
        "After the convolution layers, AlexNet used 3 FC layers, with dropouts and ReLU, finally down to 1000 outputs (number of classes).\n",
        "\n",
        "We will move on to build the entire class module with defining the layers and forward pass and then a train loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Building the AlexNet module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jh-43Al08n1N"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "qxkd4Dd0x86j",
        "tFeigPjl_MqO"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
